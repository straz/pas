<html>
<head>

<title>Year 2000 a 'bug'? Swat that word from your dictionary</title>
</head>

<body bgcolor="#FFFFFF">
<p>
<p>
<h2>Year 2000 a 'bug'?<br>Swat that word from your dictionary</h2>

<b>by Paul A. Strassmann<br><br>
Computerworld</b><br>
March 2, 1998<hr>



<TABLE BORDER=0 CELLPADDING=0 CELLSPACING=0 WIDTH=480>

<tr><td>

<font size="+4">I</font><font size="+1">t's human nature to blame
mishaps</font> on random acts. Calling a half-trillion-dollar goof the
year&nbsp;2000 "bug" fits into that pattern. And unless we stop calling it
a bug, we won't learn the most important lesson from this disaster.

<P> Associating our year 2000 misfortunes with software bugs is
widespread. My browser turned up 2,914 articles when searching for the
"year 2000 bug" text string and 692 articles when inquiring about the
"millennium bug."

<P> How did the term "bug" catch on, when there are more accurate
terms such as "screw-up," "negligence," "carelessness" or
"thoughtlessness"? The answer is plain: A bug is an unpremeditated and
unplanned occurrence, while the more appropriate words may call for a
judgment about personal accountability.

<P> The term "bug" goes back to the late Rear Adm. Grace Hopper, who
often told the story about a moth trapped inside the mechanical switch
of one of the earliest computers. She told the senior mathematicians a
bug had caused the computer to malfunction.

<P> Though moths could never block programming logic, the term
"software bug" caught on. Programmers attributed all sorts of
omissions and errors to bugs; it was a convenient term -- short and
blame-free.

<P> The word evolved, allowing the substitution of terms such as
"debugging" for program testing. Today, we see software faults labeled
as accountability-avoiding features -- as in President Clinton's
<a href="http://library.whitehouse.gov/cgi-bin/web_fetch_doc?dataset=Dataset-ExecutiveOrder&db=ExecutiveOrders&doc_id=180&query=feature">Executive Order</a> of Feb. 4, creating the Year 2000 Conversion Council
for safeguarding U.S. government computers. It refers to the year 2000
problem as a "design feature."

<P> But nothing in the history of computer jargon compares with
rationalizing managerial negligence as a random event. Calling the
year 2000 fiasco a bug suggests something as blameless as a trapped
insect. It isn't. It wasn't an error of omission but an error
committed because managers weren't diligent about the likely
consequences of the systems they built.

<P><h3>Seeking absolution through fiction</h3> 

<P> Those who talk about the year 2000 situation as a manifestation of
IT's supposedly intrinsic "bugginess" are following a well-established
pattern of behavior. Psychiatrists have written books about the
universal tendency to engage in blame-displacement when people are
confronted with a mess.

<P> The U.S. Air Force, for instance, has a long tradition of
attributing to gremlins the responsibility for maintenance mishaps.
Greeks and Roman generals would lose battles because of demons. Jewish
lore is full of stories about dybbuks that make people do all sorts of
things they later regret. The Irish deploy leprechauns, and the
Scandinavians have their trolls to account for whatever mischief may
happen.

<P> We now face the most costly technological mistake since Roman
engineers installed lead pipes that gradually poisoned much of the
population of ancient Rome. The difference is that the Roman aqueduct
builders didn't know, at least initially, the consequences of what
they were doing. IS managers can't claim ignorance or blame fictitious
creatures as a defense.

<P><h3>The explanation</h3> 

<P> Unfortunately, no one can learn anything if he's unwilling to
comprehend. The time has come to understand why analytically minded
experts would neglect fixing something that in due course would cost
untold billions. We must be candid about it rather than hide behind a
convenient bug label.

<P> How the year 2000 neglect crept in and how it compounded isn't a
mystery: The demand for IT support always exceeds available resources.
Projects with short-term payoffs -- such as fast maintenance fixes and
buying attractive new technologies -- look more appealing than
long-term investments. When management confronts a choice between
quick fix or quick payback -- as many consultants promise -- rather
than the farsighted view favored by IS management and some vendors,
the long-term approach doesn't get much of a hearing. Management
trusts the consultants more than its own staff. That's how everyone
ends up spending trillions of dollars in a continuous frenzy of
build-and-scrap cycles.

<P> The year 2000 problem covers up hundreds of other cases of
accumulated neglect that show up as decreased employee productivity,
increased overhead and unnecessary complexity. If we are to learn from
the year 2000 experience, we must see it as a lesson in managing IT
with an eye on its long-term consequences. Systems have a surprisingly
long life, databases last for decades, and software logic is
potentially immortal.

<P> Software is an investment, not an expense. Treat it that way.
Nobody will learn much from rationalizing it as a bug-prone accident.

<hr>

<font size="-1">

Strassmann (<a
href="mailto:paul@strassmann.com">paul@strassmann.com</a>) is getting
ready to fumigate bugs.  He is founder, chairman, and CEO of <a
href="http://www.stacorp.com">Software Testing Assurance Corp.</a> in
Stamford, Conn.<p>
</font>

</td></tr>
</table>

<!--#include file="cw98-footer.shtml"-->
